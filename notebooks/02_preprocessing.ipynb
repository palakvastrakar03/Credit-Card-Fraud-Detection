{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bd5adc",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This notebook prepares the credit card transactions dataset for machine\n",
    "learning by performing feature–target separation, feature scaling, and a\n",
    "stratified train-test split. No model training is performed in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4615105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from loader import load_data\n",
    "from preprocessing import (\n",
    "    split_features_target,\n",
    "    scale_amount,\n",
    "    stratified_split\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "df = load_data('../data/creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae609450",
   "metadata": {},
   "source": [
    "### Feature–Target Separation\n",
    "\n",
    "The dataset is divided into input features and the target variable (`Class`)\n",
    "to enable supervised learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591936ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split features and target\n",
    "X, y = split_features_target(df)\n",
    "\n",
    "# Check class distribution\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f114f",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance (Observation)\n",
    "\n",
    "The dataset is highly imbalanced, with fraudulent transactions representing\n",
    "a very small fraction of the data. This imbalance is preserved during splitting\n",
    "and addressed during model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a5b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled, scaler = scale_amount(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2027aba",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "The transaction amount is scaled using RobustScaler to reduce the impact of\n",
    "outliers while preserving the distribution of other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e037c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      "Class\n",
      "0    227451\n",
      "1       394\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution:\n",
      "Class\n",
      "0    56864\n",
      "1       98\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = stratified_split(X_scaled, y)\n",
    "\n",
    "print(\"Train class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86111a8c",
   "metadata": {},
   "source": [
    "## Preprocessing Complete\n",
    "\n",
    "The dataset has been successfully prepared with proper scaling and a stratified\n",
    "train-test split to prevent data leakage. The processed data is now ready for\n",
    "model training and evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
